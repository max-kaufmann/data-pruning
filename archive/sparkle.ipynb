{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# Basic layout of the notebook #\n",
    "################################\n",
    "#\n",
    "# 1. Load all prerequisites\n",
    "# 2. Create a noise generator which outputs noise parameterized by some vars.\n",
    "# 3. Create an adversary which creates adversarial images according to this noise generator.\n",
    "# 4. Write a loop to display a few images (real image, regular noise, adversarial)\n",
    "#\n",
    "# (Unused)\n",
    "# 4a. Write a loop to display a few images (real image, regular noise, adv 1, 3, 10 steps.)\n",
    "# 4b. Write a function to display the averages (real image, regular noise, adv 1, 3, 10 steps.)\n",
    "\n",
    "#########################################\n",
    "# Basic layout of the problem statement #\n",
    "#########################################\n",
    "#\n",
    "# 1. You have an image x.\n",
    "# 2. You can modifiy x by adding adversarial noise to x.\n",
    "# 2a. There are restrictions on the parameterization of the adversarial noise\n",
    "# 2b. There are restrictions on the scale of the adversarial noise (?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as trn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_transform = trn.Compose([trn.Resize(256), trn.CenterCrop(224), trn.ToTensor()])\n",
    "\n",
    "mean = torch.FloatTensor(np.array([0.485, 0.456, 0.406]).reshape(1,3,1,1))#.cuda()\n",
    "std = torch.FloatTensor(np.array([0.229, 0.224, 0.225]).reshape(1,3,1,1))#.cuda()\n",
    "\n",
    "test_data = dset.ImageFolder('/Users/oliver/datasets/imagenette2/val/', transform=test_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True,\n",
    "                                          num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_module(state_dict):\n",
    "    d = {}\n",
    "    for key in state_dict:\n",
    "        d[key[7:]] = state_dict[key]\n",
    "    return d\n",
    "\n",
    "net = models.resnet50()\n",
    "'''\n",
    "net.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "                                       model_dir='/home/hendrycks/datasets/models'))\n",
    "'''\n",
    "session = torch.load('/Users/oliver/models/deepaugment_and_augmix.pth.tar', map_location=torch.device('cpu'))\n",
    "state_dict = remove_module(session['state_dict'])\n",
    "net.load_state_dict(state_dict)\n",
    "#'''\n",
    "net.eval()\n",
    "#net.cuda()\n",
    "#cudnn.benchmark = True  # fire on all cylinders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "to_np = lambda z: z.to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def template_creator(vars, bsize):\n",
    "    noises = []\n",
    "    for i in range(bsize):\n",
    "        noise = single_template_creator(vars)\n",
    "        noises.append(noise)\n",
    "    return np.array(noises)\n",
    "\n",
    "def single_template_creator(vars):\n",
    "    '''\n",
    "    Creates some noise based on some variable.\n",
    "    Noise should be in some range.\n",
    "    '''\n",
    "    # how to remove image?\n",
    "    centers, radii, amounts, color = vars\n",
    "    randomness = 25\n",
    "    nrays = 50\n",
    "\n",
    "    def kernel(point, center, radius, ray_lengths, amount, color):\n",
    "        rays = len(ray_lengths)\n",
    "        dp = point - center\n",
    "        dist = torch.linalg.norm(dp)\n",
    "        angle = torch.arctan2(dp[1], dp[0])\n",
    "        d = (angle + np.pi) / (2 * np.pi) * rays\n",
    "        i = int(d)\n",
    "        f = d - i \n",
    "\n",
    "        if radius != 0:\n",
    "            length = ray_lengths[i % rays] + f * (ray_lengths[(i+1) % rays] - ray_lengths[i % rays])\n",
    "            g = length**2 / (dist**2 + 1e-4)\n",
    "            g = g ** ((100 - amount) / 50.0)\n",
    "            f -= 0.5\n",
    "            f = 1 - f**2\n",
    "            f *= g\n",
    "        f = np.clip(f, 0, 1)\n",
    "        return f * color\n",
    "\n",
    "    for center, rays, amount, radius in zip(centers, nrays, amounts, radii):\n",
    "        ray_lengths = [max(1,radius + randomness / 100.0 * radius * np.random.randn())\\\n",
    "            for i in range(rays)]\n",
    "\n",
    "        noise = np.array([[kernel(np.array([y,x]), center, radius, ray_lengths, amount, color)\\\n",
    "            for x in range(self.im_size)] for y in range(self.im_size)])\n",
    "\n",
    "    noise = np.clip(noise, 0, 255)\n",
    "    return noise / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TemplateAdversary(nn.Module):\n",
    "    def __init__(self, eps=0.05, scale=1, num_steps=10, step_size=0.01):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = scale\n",
    "        self.num_steps = num_steps\n",
    "        self.step_size = step_size\n",
    "\n",
    "    def forward(self, model, bx, by, x_max):\n",
    "        \"\"\"\n",
    "        :param model: the classifier's forward method\n",
    "        :param bx: batch of images\n",
    "        :param by: true labels\n",
    "        :return: perturbed batch of images\n",
    "        \"\"\"\n",
    "        bsize = bx.size(0)\n",
    "        \n",
    "        # create initial variables\n",
    "        template_vars = template_creator(vars, bsize)\n",
    "\n",
    "        # create initial images\n",
    "        adv_bx = bx.detach()\n",
    "        template = template_creator(template_vars, bsize) #[:,:,16:-16,16:-16]\n",
    "        original_template = template.clone().detach().data\n",
    "\n",
    "        # begin optimizing the inner loop\n",
    "        opt = optim.Adam(template_vars, lr=0.01)\n",
    "\n",
    "        for i in range(self.num_steps):\n",
    "            opt.zero_grad()\n",
    "\n",
    "            with torch.enable_grad():\n",
    "                template = template_creator(template_vars, bsize) #[:,:,16:-16,16:-16]\n",
    "                logits = model(((adv_bx + self.scale * template)/(x_max + self.scale) - mean)/std)\n",
    "                loss = -F.cross_entropy(logits, by, reduction='sum')\n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "            opt.step()\n",
    "            \n",
    "            # clamp variables\n",
    "            for i in range(len(template_vars)):\n",
    "                template_vars[i].detach()\n",
    "                template_vars[i].data = template_vars[i].data.clamp(0, self.eps)\n",
    "                template_vars[i].requires_grad_()\n",
    "\n",
    "        return template, original_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scale = 1\n",
    "eps = 0.05\n",
    "adv = TemplateAdversary(eps, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, (x, label) in enumerate(test_loader):\n",
    "    if i < 3:\n",
    "    \n",
    "        print('\\nClean Image')\n",
    "        target = torch.LongTensor([label])#.cuda()\n",
    "\n",
    "        x = x#.cuda()\n",
    "        x_max, _ = torch.max(x.view(x.size(0), 3, -1), -1)\n",
    "        x_max = x_max.view(-1, 3, 1, 1)\n",
    "\n",
    "        logits = net((x - mean)/std)\n",
    "        print('Loss:', to_np(F.cross_entropy(logits, target)))\n",
    "        print(['Wrong Prediction', 'Right Prediction'][int(label == to_np(torch.argmax(logits, 1))[0])])\n",
    "        \n",
    "        plt.subplot(1,2,1) # induced for comparable size\n",
    "        plt.imshow(to_np(x).squeeze().transpose((1,2,0)))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        print('\\nInitial Template')\n",
    "\n",
    "        adv_template, original_template = adv(net, x, target, x_max)\n",
    "        \n",
    "        logits = net(((x + scale * original_template)/(x_max + scale) - mean)/std)\n",
    "        print('Loss:', to_np(F.cross_entropy(logits, target)))\n",
    "        print(['Wrong Prediction', 'Right Prediction'][int(label == to_np(torch.argmax(logits, 1))[0])])\n",
    "        \n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(to_np((x + scale * original_template)/(x_max + scale)).squeeze().transpose((1,2,0)))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(to_np(original_template).squeeze(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        print('\\nAdversarial Template')\n",
    "        \n",
    "        logits = net(((x + scale * adv_template)/(x_max + scale) - mean)/std)\n",
    "        print('Loss:', to_np(F.cross_entropy(logits, target)))\n",
    "        print(['Wrong Prediction', 'Right Prediction'][int(label == to_np(torch.argmax(logits, 1))[0])])\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(to_np((x + scale * adv_template)/(x_max + scale)).squeeze().transpose((1,2,0)))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(to_np(adv_template).squeeze(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}